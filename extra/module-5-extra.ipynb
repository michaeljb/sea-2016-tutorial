{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "<p style=\"float:right\">\n",
    "<img src=\"../images/logos/cu.png\" style=\"display:inline\" />\n",
    "<img src=\"../images/logos/cires.png\" style=\"display:inline\" />\n",
    "<img src=\"../images/logos/nasa.png\" style=\"display:inline\" />\n",
    "<img src=\"../images/logos/nsidc_daac.png\" style=\"display:inline\" />\n",
    "</p>\n",
    "\n",
    "# Python, Jupyter & pandas: Module 5 Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting geolocated data with xarray\n",
    "\n",
    "Let's use what we know about our source data to write a couple of routines to compute anomalies and display them on a map.\n",
    "\n",
    "First, some setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f nhsce_v01r01_19661004_20160201.nc\n",
    "unzip $PWD/../data/nhsce_v01r01_19661004_20160201.nc.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "snowcover_file = 'nhsce_v01r01_19661004_20160201.nc'\n",
    "dataset = xr.open_dataset(snowcover_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the [`DataSet.groupby`](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.groupby.html) function to gather groups of time dimensions. We'll group all of the time index values by the month number.  Accessing the `groups` attribute returns a dictionary where the keys are months and the values are a list of indices into the dataset time index for that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "month_indices = dataset.groupby('time.month').groups\n",
    "\n",
    "print(\"Keys:\", month_indices.keys(), \"<-- One for each month\")\n",
    "print(\"Feburary Indices:\", month_indices[2][0:5], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We can use a list of indices to select data with `isel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "month_num = 6\n",
    "\n",
    "weeks = dataset['time'].isel(time=month_indices[month_num])\n",
    "\n",
    "print(\"first 10 dataSet['time'] Values:\\n \", weeks.values[0:10])\n",
    "print(\"\\nTotal number of elements in month_indices:\", len(weeks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We'll use every available measurement in the `DataSet` to compute a median snow cover for a given month.\n",
    "\n",
    "We'll do this by computing a mean across time for each of the month's samples. This gives us a fracional probability of any measurement having snow cover. By taking those values that are greater than or equal to .5, we get a median snow cover for the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Choose a month with some snow and compute median snow cover for that month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "month_number = 2\n",
    "average_snowcover = dataset['snow_cover_extent'].isel(time=month_indices[month_number]).mean(dim='time')\n",
    "median_snowcover = average_snowcover > .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract our latitude, longitude and land variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "lats = dataset.latitude.values\n",
    "lons = dataset.longitude.values\n",
    "land = dataset.land.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Create a function that will return a categorical grid of the snow cover anomaly. For each cell, we want to identify whether it is part of the selected month's extent and/or median extent, or if it is land or ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def anomaly_snowcover(selected_snow_cover, median_snowcover, land):\n",
    "\n",
    "    sel = selected_snow_cover.values.astype(bool)\n",
    "    med = median_snowcover.values.astype(bool)\n",
    "    land = land.astype(bool)\n",
    "\n",
    "    # Do logical intersections of the data\n",
    "    both     =  sel &  med\n",
    "    only_med = ~sel &  med\n",
    "    only_sel =  sel & ~med\n",
    "\n",
    "    # Assign a those intersections values.\n",
    "    out = np.zeros_like(land.astype(int))\n",
    "    out[~land] = 0\n",
    "    out[land] = 1\n",
    "    out[both] = 2\n",
    "    out[only_med] = 3\n",
    "    out[only_sel] = 4\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Create a [colormap](http://matplotlib.org/api/colors_api.html?highlight=listedcolormap#matplotlib.colors.ListedColormap) and [normalizer](http://matplotlib.org/users/colormapnorms.html) for plotting the `anomaly_snowcover` output, knowing our data will have only values 0 through 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Choose some nice colors\n",
    "categorical_cmap = mpl.colors.ListedColormap(colors=['#D4EFFA', '#A3BAA5','#FEFEFE','#BC80BC', '#ACD665'])\n",
    "\n",
    "# center your bounds around your datapoint.\n",
    "bounds = [-.5, .5, 1.5, 2.5, 3.5, 4.5]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, categorical_cmap.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some other libraries we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Now use a widget to plot anomalies of snow cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import calendar as cal\n",
    "\n",
    "def title_function(datetime64ns):\n",
    "    date = datetime64ns.astype('M8[ms]').astype(dt.date)\n",
    "    return \"Snow Cover: {0}-{1} compared to median\".format(cal.month_abbr[date.month], date.year)\n",
    "\n",
    "def selected_month_label(datetime64ns):\n",
    "    date = datetime64ns.astype('M8[ms]').astype(dt.date)\n",
    "    return '{0} {1} Only'.format(cal.month_abbr[date.month], date.year)\n",
    "\n",
    "@interact(index_in=widgets.IntSlider(min=0,\n",
    "                                     max=len(month_indices[month_number])-1,\n",
    "                                     step=1,\n",
    "                                     value=0,\n",
    "                                     continuous_update=False))\n",
    "\n",
    "def plot_anomaly(index_in=0):\n",
    "    index = month_indices[month_number][index_in]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    m = Basemap(projection='npstere', boundinglat=30, lon_0=-45)\n",
    "    m.drawcoastlines()\n",
    "\n",
    "    parallels = np.arange(0, 90, 20)\n",
    "    m.drawparallels(parallels, labels=[True])\n",
    "    meridians = np.arange(-180, 180, 45)\n",
    "    m.drawmeridians(meridians, labels=[True, True, False, True, True, True, True, True])\n",
    "    \n",
    "    the_data = anomaly_snowcover(dataset['snow_cover_extent'].isel(time=index), median_snowcover, land)\n",
    "    m.pcolor(lons, lats, the_data, latlon=True, cmap=categorical_cmap, norm=norm)\n",
    "    \n",
    "    times = dataset['time'].isel(time=index).values\n",
    "    \n",
    "    cbar = plt.colorbar(ticks=[0, 1, 2, 3, 4], norm=norm)\n",
    "    cbar.set_ticklabels(['Ocean', 'Land', 'Both', 'Median Only', selected_month_label(times)])\n",
    "    plt.title(title_function(times))\n",
    "    plt.draw()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "Python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "module-3.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
