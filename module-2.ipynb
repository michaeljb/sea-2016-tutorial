{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "<p style=\"float:right\">\n",
    "<img src=\"images/logos/cu.png\" style=\"display:inline\" />\n",
    "<img src=\"images/logos/cires.png\" style=\"display:inline\" />\n",
    "<img src=\"images/logos/nasa.png\" style=\"display:inline\" />\n",
    "<img src=\"images/logos/nsidc_daac.png\" style=\"display:inline\" />\n",
    "</p>\n",
    "\n",
    "# Python, Jupyter & pandas: Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining data and basic inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data access\n",
    "\n",
    "It is, of course, possible to obtain data (roughly construed -- we'll look at images here because they're simple to view) outside Jupyter -- or via one of the script (e.g. `%%bash`) magics, which saves the trouble of opening a separate terminal / command / browser window).\n",
    "\n",
    "Here we fetch an image to the local filesystem, then display it with Markdown (you may need to double-click the Markdown cell below the code and re-evalute it with Shift+Enter or the \"play\" button in the toolbar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "imgfile='N_197902_extn_v2.png'\n",
    "rm -f $imgfile\n",
    "wget ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Feb/$imgfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "<img src='N_197902_extn_v2.png' style='float:left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We can also obtain an image directly from the Internet and display in with Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Feb/N_201602_extn_v2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "The `netCDF4` package provides an OPeNDAP client. Here we use it to obtain data via an OPeNDAP server at NSIDC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "\n",
    "url_basic = ('http://opendap.apps.nsidc.org:80/opendap/DATASETS/'\n",
    "             'nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc'\n",
    ")\n",
    "\n",
    "dataset_basic = netCDF4.Dataset(url_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "### Data inspection\n",
    "\n",
    "We can inspect the `dataset_basic` object to see its class. In this case, it's exactly what we'd expect given that we created it with `netCDF4.Dataset`. However, it's sometimes the case, especially when working with a new library, that we do not anticipate the type of an object returned from some method / function call, so it's handy to be able to find out what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "type(dataset_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Given that we have a `Dataset` object from the `netCDF4` library, we could of course go consult [that library's documentation](https://netcdf4-python.googlecode.com/svn/trunk/docs/netCDF4.Dataset-class.html) to learn what kinds of attributes and methods such an object has.\n",
    "\n",
    "Or, we can bravely plunge in and have a look for ourselves.\n",
    "\n",
    "The most general kind of inspection we can do is to simply ask an object to express itself as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "In this case, we get lots of useful information. Not all Python objects are so helpful.\n",
    "\n",
    "Well-written Python code includes so-called _docstrings_, which we can access via the built-in `help` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "help(dataset_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "In this case, we get extensive -- and quite helpful -- information on the `Dataset` object.\n",
    "\n",
    "We can also use Python's built-in `dir` command to get a list of object members. This mechanism can be helpful even in cases where docstrings are unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dir(dataset_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Unfortunately, this list includes attributes and/or methods, not intended for end-users like us. The convention in Python is to name \"private\" attributes/methods with one or more leading underscores. Here, we filter out those members:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in dir(dataset_basic) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "This is getting closer, but there's still a lot here that may not be of interest to us. Since this is NetCDF data, though, we can call the [`ncattrs`](https://netcdf4-python.googlecode.com/svn/trunk/docs/netCDF4.Dataset-class.html#ncattrs) method on our `dataset_basic` variable to get an even more specific list of this dataset's global attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_basic.ncattrs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We can inspect these attributes to see their values, which match information on [this dataset's documentation page](http://nsidc.org/data/docs/measures/nsidc-0530/index.html) at NSIDC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_basic.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_basic.institution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "The actual data is available under `variables`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "for variable in dataset_basic.variables:\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Note that these variables correspond to those listed in Table 3 of the documentation page linked to above.\n",
    "\n",
    "Let's extract the `latitude` variable and look at its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "latitude = dataset_basic.variables['latitude']\n",
    "latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "So, `latitude` is a 720 x 720 array, with valid values ranging from -90 to 90 degrees north, and invalid (\"fill\") marked as -999.\n",
    "\n",
    "Since we pulled `latitude` out of another object, rather than creating it explicitly as we did with the `Dataset`, what kind of object do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "type(latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Makes sense. And how are the data in this variable represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "latitude.datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "As 32-bit floating-point numbers. We also saw, but might not have noticed, this when we printed `latitude`, above: Note the `float32` designation in the second line. Similarly, all the other data shown above can be extracted with more targeted queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "latitude.long_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "latitude.valid_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "latitude.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Just as with our `Dataset`, we can look at all the public attributes and methods of our `Variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "[x for x in dir(latitude) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Instances of the `Variable` class (like our `latitude` object) from `netCDF4` behave like multidimensional arrays, similar to NumPy's `ndarray`. So, we can access elements with the familiar `[]` bracket notation. Since we know that `latitude` is 720 x 720, as we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "len(latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "And if we look at the first row in the `latitude` array, its length is similarly what we'd expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "len(latitude[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Note that Python is zero-indexed like C, and unlike Fortran, so valid indices range from 0 to 719."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Let's extract the `time` variable from our dataset and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "time = dataset_basic.variables['time']\n",
    "print(time)\n",
    "print(time[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "So, this dataset's data starts 4749 days after 1998-12-31 on the Gregorian calendar. Let's convert that information into something more useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "units = time.units\n",
    "print('units: %s' % units)\n",
    "value = time[0]\n",
    "print('value: %s' % value)\n",
    "print(' date: %s' % netCDF4.num2date([value], units)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Happily, this agrees with the URL we used to request this data in the first place. If we had a directory full of data files to process, we could obtain this information internally rather than relying on metadata encoded in filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Out of curiosity, let's check that the `longitude` variable's shape conforms to that of `latitude`, as we'd hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "longitude = dataset_basic.variables['longitude']\n",
    "longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Good, it is 720 x 720 just like `latitude`.\n",
    "\n",
    "Now let's look at one of the actual snow cover variables which, presumably, is why we're bothering with this dataset in the first place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "msce_full = dataset_basic.variables['merged_snow_cover_extent']\n",
    "msce_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Inspecting the Merged Snow Cover Extent variable, we see that the data is in a 720 x 720 array (the dimensions match those of latitude and longitude, so that's good!) whose values are integers specifying snow cover information from various sources, as well as snow-free and ice-covered land, and ocean.\n",
    "\n",
    "A \"fill\" value of -99 is used to indicate bad or unavailable data.\n",
    "\n",
    "We can pick a \"random\" array element and see its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "msce_full[0][360][360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "40 = Ocean. Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(latitude[360][360])\n",
    "print(longitude[360][360])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "That's pretty close to the north pole, in the Arctic Ocean, so seems reasonable.\n",
    "\n",
    "Let's do a quick-and-dirty visualization of this data as another reality check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(msce_full[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Looking down on the North Pole, we can recognize familiar geographic shapes: North America to the left, Asia to the right, and Greenland in yellow near the center. Note that the scale of the axes are in rows and columns, not latitudes and longitudes. Still, this is a helpful visual verification that we are looking at reasonable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Let's use NumPy to convert our `msce_full` variable into an `ndarray` object, and get rid of that useless first dimension. NumPy's `squeeze` method removes all trivial (one-element) dimensions from a multidimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "msce_squeezed = np.squeeze(msce_full)\n",
    "msce_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "That's better. Now `msce_squeezed`'s shape matches that of `latitude` and `longitude`.\n",
    "\n",
    "How much _good_ data do we have in `msce_squeezed`? That is, how many data elements are there in total vs those set to the fill value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "print(msce_squeezed.size)\n",
    "print(msce_squeezed[msce_squeezed != -99].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "So, over 20% of the data elements are set to the fill value. This sometimes happens with satellite (and other data): Quality Control (QC) algorithms determine that some observations are suspect, so they are marked as such so that further analysis can avoid depending on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "In this case, though, and comparing to our simple visualization of the data, above, we can see that the \"bad\" values simply lie in positions of the 720 x 720 grid that do not fall on the Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "plt.imshow(msce_squeezed == -99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "### Subsetting data with OPeNDAP\n",
    "\n",
    "One benefit to using OPeNDAP for data access is that data can be subsetted prior to download, to avoid the transfer and storage of data one is not interested in.\n",
    "\n",
    "NSIDC's [OPeNDAP Server Dataset Access Form](http://opendap.apps.nsidc.org/opendap/DATASETS/nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc.html) for this data gives some guidance on subsetting the data. For starters, let's restrict our query to the three variables -- Latitude, Longitude, and Merged Snow Cover Extent -- that we are interested in. When we tick the checkboxes for _latitude_, _longitude_, and *merged_snow_cover_extent*, the URL shown in the _Data URL_ field is updated to:\n",
    "\n",
    "`http://opendap.apps.nsidc.org:80/opendap/DATASETS/nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc?latitude[0:1:719][0:1:719],longitude[0:1:719][0:1:719],merged_snow_cover_extent[0:1:0][0:1:719][0:1:719]`\n",
    "\n",
    "Let's perform our query and data again with this URL and check the variables we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "url_min = ('http://opendap.apps.nsidc.org:80/opendap/DATASETS/'\n",
    "           'nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc?'\n",
    "           'latitude[0:1:719][0:1:719],'\n",
    "           'longitude[0:1:719][0:1:719],'\n",
    "           'merged_snow_cover_extent[0:1:0][0:1:719][0:1:719]'\n",
    ")\n",
    "\n",
    "dataset_min = netCDF4.Dataset(url_min)\n",
    "\n",
    "for variable in dataset_min.variables:\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Previously, we had ten variables; now we have only three. Nice.\n",
    "\n",
    "Let's say we're only interested in snow cover in Iceland. Let's subset the data geographically as well. The [OPeNDAP Server Dataset Access Form](http://opendap.apps.nsidc.org/opendap/DATASETS/nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc.html) gives us options for constraining the variables, but expects us to do so by row and column. Iceland lies between 12 to 25 degrees west, and 63 to 67 degrees north. Let's find out which rows and columns in our `Dataset` fall within those bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "We'll extract the data from our NetCDF `latitude` and `longitude` variables, then construct a boolean mask corresponding to values that surround Iceland. Since `latitude` and `longitude` have matching 720 x 720 shapes, our mask gets the same shape, and is composed of elements where **all** the conditions hold true. Note the use of the bitwise-and `&` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "lat = dataset_min.variables['latitude'][:, :]\n",
    "lon = dataset_min.variables['longitude'][:, :]\n",
    "in_range = (lat >= 63) & (lat <= 67) & (lon >= -25) & (lon <= -12)\n",
    "in_range.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many grid points match these criteria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(in_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how do they look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(in_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Let's use NumPy's [`where()`](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.where.html) function get row and column locations where `in_range` is true. This filters out all locations where the `in_range` conditions are `False`, so we should be able to sample `in_range` at selected `row` and `col` points and verify that we only see `True` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "row, col = np.where(in_range)\n",
    "print(in_range[row[0:5], col[0:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that `row` and `col` now represent only those rows and columns containing our area of Icelandic interest, we can compute a bounding box from the row/column minima and maxima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "bbox = np.min(row), np.max(row), np.min(col), np.max(col)\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Now let's use our bounding-box values as constraints in our OPeNDAP URL to select just the rows and columns that we think correspond to Iceland. The OPeNDAP constraints are given in `lower_bound:stride:upper_bound` form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "url_min_iceland = ('http://opendap.apps.nsidc.org:80/opendap/DATASETS/'\n",
    "                   'nsidc0530_MEASURES_nhsnow_daily25/2012/nhtsd25e2_20120101_v01r01.nc?'\n",
    "                   'latitude[453:1:476][310:1:338],'\n",
    "                   'longitude[453:1:476][310:1:338],'\n",
    "                   'merged_snow_cover_extent[0:1:0][453:1:476][310:1:338]'\n",
    ")\n",
    "\n",
    "dataset_min_iceland = netCDF4.Dataset(url_min_iceland)\n",
    "dataset_min_iceland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the line `dimensions(sizes): time(1), cols(29), rows(24)`: 24 rows and 29 columns, which corresponds to our request. This is a lot less data than we were getting with the full 720 x 720 grids!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "In Module 3, we'll display this geolocated data and see if we really got what we asked for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "name": "module-2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
